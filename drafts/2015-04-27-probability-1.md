---
title: Notes on probability theory, part 1
---

Probability is, to at least some extent, about measuring the likelihood of events. So it seems to me that the probability theory that follows is an attempt to formalize ideas about such measurement.


## Algebras and $\sigma$-algebras

An **algebra of sets** (hereafter referred to just as an **algebra**) for our purposes here is a non-empty collection of subsets of some set $E$ that is closed under

 - complements
 - finite unions
 - finite intersections

A **$\sigma$-algebra** is like an algebra, but closed under *countable* unions/intersections instead of merely finite unions/intersections.

Any $\sigma$-algebra on $E$ must contain $\emptyset$ and $E$ (Proof: $\sigma$-algebras are non-empty, so any given $\sigma$-algebra must contain some set $S$ and hence contain $S^c$ and $S \cup S^c = E$.) It is routine to verify that $\{\emptyset, E\}$ is a $\sigma$-algebra on $E$, called the **trivial $\sigma$-algebra**. Another example of a $\sigma$-algebra is the powerset of $E$ (verify it!), called the **discrete $\sigma$-algebra**.

There are algebras that are not $\sigma$-algebras. A common example: for any infinite set $X$, the collection consisting of both finite subsets of $X$ and complements of finite subsets of $X$ (sometimes called *co-finite* subsets). You can prove that it's an algebra. However, it is *not* a $\sigma$-algebra since the countably infinite union of finite sets may be infinite but not co-finite. Consider $X$ as the integers and the countable union

$$\bigcup_{i=1}^{\infty} \{ i \}$$

This is a countably infinite union of singleton sets $\{i\}$ for $i = 1, 2, 3, \ldots$. The union is the set $\{z \in \mathbb{Z} : z \geq 1\}$, which is infinite but not co-finite since it lacks zero and every negative integer.

## Measurable space

A **measurable space** is a pair $(X, \mathcal{A})$ where $X$ is a set and $\mathcal{A}$ is a $\sigma$-algebra. The elements of $\mathcal{A}$ are called the **measurable sets**.

## Some other stuff about $\sigma$-algebras

You can probably skip the next two subsections if the math is overwhelming.

### Generated $\sigma$-algebras

The intersection of an arbitrary collection of $\sigma$-algebras is again a $\sigma$-algebra (prove it). This allows us to *generate* $\sigma$-algebras from an arbitrary collection of subsets: if $\mathcal{C}$ is any collection of subsets of $E$, the **$\sigma$-algebra generated by $\mathcal{C}$** is defined to be the intersection of all $\sigma$-algebras on $E$ that contain it. This will be deoted by $\sigma \mathcal{C}$.

Note that $\sigma \mathcal{C}$ can be thought of as the smallest $\sigma$-algebra containing $\mathcal{C}$.

### Borel algebras

When $E$ is a topological space, the $\sigma$-algebra generated by its topology is called the **Borel $\sigma$-algebra** on $E$, and will be denoted by $\mathcal{B}(E)$. The elements of this $\sigma$-algebra are called **Borel-measurable sets**, or just **Borel sets**. So the open subsets, in particular, are each Borel-measurable.

Borel algebras of particular importance are the ones on the standard $d$-dimensional Euclidean space $\mathbb{R}^d$. Here $\mathbb{R}^d$ is taken to have its standard metric topology. Of course when $d = 1$ we have a Borel algebra on the real line.


## Probability spaces

In what follows, to say "$(X, \mathcal{A})$ is a measurable space", is to say that $\mathcal{A}$ is a $\sigma$-algebra for $X$.

From now on, we'll use $\Omega$ to denote the set on which a $\sigma$-algebra $\mathcal{E}$ is defined. Let's call $\Omega$ the **sample space**, and the sets in $\mathcal{E}$ the **events**.

You should think of $\Omega$ as the collection of all possible outcomes for a random trial. An event is then some collection of outcomes. For example, to model rolling a fair, six-sided die, we can use the sample space $\Omega = \{1, 2, 3, 4, 5, 6\}$. One example of an event is then $\{1, 2, 3\}$, which is the event of rolling a number less than or equal to 3. Similarly, $\{2, 4, 6\}$ is the event of rolling an even value. Another example of a random trial is rolling two dice. In this case the sample space is $\Omega = \{(i, j) : 1 \leq i, j \leq 6 \}$. The event $\{(1, 1)\}$ is the familiar [snake eyes](http://en.wikipedia.org/wiki/Snake_eyes).


If $(\Omega, \mathcal{E})$ is some measurable space, a  **probability measure** on $(\Omega, \mathcal{E})$ is defined to be a function

$$\mathbb{P}: \mathcal{E} \to [0, \infty)$$

that has these properties:

 - $\mathbb{P}(\emptyset) = 0$
 - If $\{A_1, A_2, A_3, \ldots\}$ is a countable collection of pairwise disjoint events, then $\mathbb{P}(\bigcup_1^{\infty} A_i) = \sum_1^{\infty} \mathbb{P}(A_i)$$
 - $\mathbb{P}(\Omega) = 1$

A **probability space** is defined to be a triple $(\Omega, \mathcal{E}, \mathbb{P})$ where $(\Omega, \mathcal{E})$ is a measurable space and $\mathbb{P}$ is a probability measure for $(\Omega, \mathcal{E})$


## Conclusion

Now that we've defined probability spaces, the task is to first prove basic properties about these spaces. After that we'll define and study measurable functions.
